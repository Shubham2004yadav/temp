{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubham2004yadav/temp/blob/main/LLPS_vs_non_LLPS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yTKBdTDosqn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/Zhou-Yetong/Opt_PredLLPS.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Opt_PredLLPS/datasets\n",
        "!pip install biopython"
      ],
      "metadata": {
        "id": "Nfz3AEqoo6Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Zhou-Yetong/Opt_PredLLPS.git\n"
      ],
      "metadata": {
        "id": "vPhDM_ydpFcc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls Opt_PredLLPS/datasets\n"
      ],
      "metadata": {
        "id": "xvw-xiflpZ86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio import SeqIO\n",
        "import pandas as pd\n",
        "\n",
        "# Load LLPS (positive) sequences\n",
        "llps_records = list(SeqIO.parse(\"Opt_PredLLPS/datasets/LLPS.fasta\", \"fasta\"))\n",
        "\n",
        "# Load non-LLPS (negative) sequences\n",
        "non_llps_records = list(SeqIO.parse(\"Opt_PredLLPS/datasets/non_LLPS.fasta\", \"fasta\"))\n"
      ],
      "metadata": {
        "id": "PenqOIXNrJaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame\n",
        "llps_df = pd.DataFrame({\n",
        "    'sequence': [str(rec.seq) for rec in llps_records],\n",
        "    'label': ['LLPS'] * len(llps_records)\n",
        "})\n",
        "\n",
        "non_llps_df = pd.DataFrame({\n",
        "    'sequence': [str(rec.seq) for rec in non_llps_records],\n",
        "    'label': ['non-LLPS'] * len(non_llps_records)\n",
        "})\n",
        "\n",
        "# Combine both\n",
        "df = pd.concat([llps_df, non_llps_df], ignore_index=True)\n",
        "df.sample(5)  # View random 5 rows\n"
      ],
      "metadata": {
        "id": "YJl0cKdZrkQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install biopython\n"
      ],
      "metadata": {
        "id": "22o-mdL1rwWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "\n",
        "# Define amino acid volume (Ã…^3) and polarity (Grantham scale) dictionaries\n",
        "aa_volume = {\n",
        "    'A':  88.6, 'R': 173.4, 'N': 114.1, 'D': 111.1, 'C': 108.5,\n",
        "    'Q': 143.8, 'E': 138.4, 'G':  60.1, 'H': 153.2, 'I': 166.7,\n",
        "    'L': 166.7, 'K': 168.6, 'M': 162.9, 'F': 189.9, 'P':  112.7,\n",
        "    'S':  89.0, 'T':  116.1, 'W': 227.8, 'Y': 193.6, 'V':  140.0\n",
        "}\n",
        "aa_polarity = {\n",
        "    'A':   8.1, 'R':  10.5, 'N':  11.6, 'D':  13.0, 'C':   5.5,\n",
        "    'Q':  10.5, 'E':  12.3, 'G':   9.0, 'H':  10.4, 'I':   5.2,\n",
        "    'L':   4.9, 'K':  11.3, 'M':   5.7, 'F':   5.2, 'P':   8.0,\n",
        "    'S':   9.2, 'T':   8.6, 'W':   5.4, 'Y':   6.2, 'V':   5.9\n",
        "}\n",
        "\n",
        "def compute_features(seq):\n",
        "    \"\"\"Compute selected features for a protein sequence.\"\"\"\n",
        "    seq = seq.upper()\n",
        "    analysis = ProteinAnalysis(seq)\n",
        "    # Calculate features\n",
        "    hydrophobicity = analysis.gravy()\n",
        "    aromaticity = analysis.aromaticity()\n",
        "    pI = analysis.isoelectric_point()\n",
        "    net_charge = analysis.charge_at_pH(7.0)\n",
        "    # Average side-chain volume and polarity\n",
        "    vol = sum(aa_volume.get(aa, 0) for aa in seq) / len(seq)\n",
        "    pol = sum(aa_polarity.get(aa, 0) for aa in seq) / len(seq)\n",
        "    return pd.Series({\n",
        "        'hydrophobicity': hydrophobicity,\n",
        "        'aromaticity':    aromaticity,\n",
        "        'pI':             pI,\n",
        "        'net_charge':     net_charge,\n",
        "        'volume':         vol,\n",
        "        'polarity':       pol\n",
        "    })\n",
        "\n",
        "# Apply to each sequence\n",
        "features_df = df['sequence'].apply(compute_features)\n",
        "df = pd.concat([df, features_df], axis=1)\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "8GZwPCQNrrbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['label_enc'] = df['label'].map({'LLPS': 1, 'non-LLPS': 0})\n"
      ],
      "metadata": {
        "id": "mTZG5Swprzqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[['hydrophobicity','volume','polarity','aromaticity','pI','net_charge']]\n",
        "y = df['label_enc']\n"
      ],
      "metadata": {
        "id": "viPfGCjJsYpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=104, stratify=y)\n"
      ],
      "metadata": {
        "id": "XF_0WkAesdm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2, stratify=y)  # no random_state\n"
      ],
      "metadata": {
        "id": "YTG1FHqPtxOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(random_state=104)\n",
        "clf.fit(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "BuFS7nR2sgtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy on test set: {accuracy:.2f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion matrix:\\n\", cm)\n",
        "\n",
        "\n",
        "\n",
        "# Optional: detailed classification report\n",
        "print(classification_report(y_test, y_pred, target_names=['non-LLPS','LLPS']))\n"
      ],
      "metadata": {
        "id": "X5yjuqkPsksr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we are taking random state defined not varying , this fucrion is just for fidning the highest accuracy state\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "best_accuracy = 0\n",
        "best_seed = None\n",
        "\n",
        "for seed in range(1000):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=0.2, random_state=seed, stratify=y)\n",
        "\n",
        "    clf = DecisionTreeClassifier(random_state=seed)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if acc > best_accuracy:\n",
        "        best_accuracy = acc\n",
        "        best_seed = seed\n",
        "\n",
        "print(f\"Best accuracy: {best_accuracy:.2f} with seed: {best_seed}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "3buEaQ3Kr785"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import tree\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "tree.plot_tree(clf, feature_names=X.columns, class_names=['non-LLPS','LLPS'], filled=True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GFkxVuCYso0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
        "\n",
        "# Predefined property scales\n",
        "aa_volume = {\n",
        "    'A': 88.6, 'R': 173.4, 'N': 114.1, 'D': 111.1, 'C': 108.5,\n",
        "    'Q': 143.8, 'E': 138.4, 'G': 60.1, 'H': 153.2, 'I': 166.7,\n",
        "    'L': 166.7, 'K': 168.6, 'M': 162.9, 'F': 189.9, 'P': 112.7,\n",
        "    'S': 89.0, 'T': 116.1, 'W': 227.8, 'Y': 193.6, 'V': 140.0\n",
        "}\n",
        "aa_polarity = {\n",
        "    'A': 8.1, 'R': 10.5, 'N': 11.6, 'D': 13.0, 'C': 5.5,\n",
        "    'Q': 10.5, 'E': 12.3, 'G': 9.0, 'H': 10.4, 'I': 5.2,\n",
        "    'L': 4.9, 'K': 11.3, 'M': 5.7, 'F': 5.2, 'P': 8.0,\n",
        "    'S': 9.2, 'T': 8.6, 'W': 5.4, 'Y': 6.2, 'V': 5.9\n",
        "}\n",
        "\n",
        "def compute_physicochemical_features(sequence):\n",
        "    sequence = sequence.upper()\n",
        "    analysis = ProteinAnalysis(sequence)\n",
        "\n",
        "    features = {\n",
        "        'hydrophobicity': analysis.gravy(),\n",
        "        'aromaticity': analysis.aromaticity(),\n",
        "        'volume': sum(aa_volume.get(aa, 0) for aa in sequence) / len(sequence),\n",
        "        'polarity': sum(aa_polarity.get(aa, 0) for aa in sequence) / len(sequence),\n",
        "        'pI': analysis.isoelectric_point(),\n",
        "        'net_charge': analysis.charge_at_pH(7.0),\n",
        "        'instability_index': analysis.instability_index(),\n",
        "        'molecular_weight': analysis.molecular_weight()\n",
        "    }\n",
        "    return features\n"
      ],
      "metadata": {
        "id": "9lwCYpNVsuJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply feature function to all sequences\n",
        "feature_dicts = []\n",
        "labels = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    seq = row['sequence']\n",
        "    label = 1 if row['label'] == 'LLPS' else 0\n",
        "    try:\n",
        "        feats = compute_physicochemical_features(seq)\n",
        "        feature_dicts.append(feats)\n",
        "        labels.append(label)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping sequence due to error: {e}\")\n"
      ],
      "metadata": {
        "id": "3iqZ8p-Ai9y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_df = pd.DataFrame(feature_dicts)\n",
        "features_df['label'] = labels\n",
        "features_df.head()\n"
      ],
      "metadata": {
        "id": "TRSbONdBjBYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary format: {index: {'hydrophobicity': ..., 'volume': ..., ...}, ...}\n",
        "feature_dictionary = features_df.drop(columns=['label']).to_dict(orient='index')\n"
      ],
      "metadata": {
        "id": "vWy0AVFfjEGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Analyzing {len(df)} proteins in the dataset\")"
      ],
      "metadata": {
        "id": "-iUEqA06rjDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "\n",
        "X = features_df.drop(columns=['label']).values\n",
        "y = features_df['label'].values\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# FDA (LDA)\n",
        "lda = LDA(n_components=1)\n",
        "X_lda = lda.fit_transform(X, y)\n"
      ],
      "metadata": {
        "id": "H0_hgtOSjNen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Suppose df is already defined and has a column 'sequence'\n",
        "# Example:\n",
        "# df = pd.DataFrame({'sequence': ['MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQANL...',\n",
        "#                                 'GATRAGGATGAGGAGAGAGAGAGTGCTAGCTCCTG...',\n",
        "#                                 ...],\n",
        "#                    'label':   ['LLPS', 'non-LLPS', ...]})\n",
        "\n",
        "# List the 20 standard amino acids in a fixed order\n",
        "aa_list = ['A','C','D','E','F','G','H','I','K','L',\n",
        "           'M','N','P','Q','R','S','T','V','W','Y']\n",
        "\n",
        "def compute_aac_dict(sequence):\n",
        "    \"\"\"\n",
        "    Given a protein sequence string, return a dict of\n",
        "    normalized frequencies for each of the 20 amino acids.\n",
        "    \"\"\"\n",
        "    seq = sequence.upper()\n",
        "    length = len(seq)\n",
        "    # Initialize counts to zero for each amino acid\n",
        "    counts = {aa: 0 for aa in aa_list}\n",
        "    # Count occurrences\n",
        "    for aa in seq:\n",
        "        if aa in counts:\n",
        "            counts[aa] += 1\n",
        "    # Normalize by length to get frequency\n",
        "    aac = {aa: counts[aa] / length for aa in aa_list}\n",
        "    return aac\n",
        "\n",
        "# Build the full dictionary for all rows in df\n",
        "aac_dict = {}\n",
        "for idx, row in df.iterrows():\n",
        "    seq = row['sequence']\n",
        "    aac_dict[idx] = compute_aac_dict(seq)\n",
        "\n",
        "# Example: print AAC for the first 3 proteins\n",
        "for i in range(100):\n",
        "    print(f\"Protein index {i}:\")\n",
        "    print(aac_dict[i])\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "FFR8LVLTjRon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Assuming df is already defined with 'sequence' and 'label' columns\n",
        "# Example df:\n",
        "# df = pd.DataFrame({\n",
        "#     'sequence': ['MKTAYIAKQRQISFVKSHFSRQLEERLGLIEVQANL',\n",
        "#                  'GATRAGGATGAGGAGAGAGAGAGTGCTAGCTCCTG',\n",
        "#                  ...],\n",
        "#     'label': ['LLPS', 'non-LLPS', ...]\n",
        "# })\n",
        "\n",
        "# List of 20 standard amino acids\n",
        "aa_list = ['A','C','D','E','F','G','H','I','K','L',\n",
        "           'M','N','P','Q','R','S','T','V','W','Y']\n",
        "\n",
        "def compute_aac_dict(sequence):\n",
        "    \"\"\"Compute amino acid composition for a given sequence.\"\"\"\n",
        "    seq = sequence.upper()\n",
        "    length = len(seq)\n",
        "    counts = {aa: 0 for aa in aa_list}\n",
        "    for aa in seq:\n",
        "        if aa in counts:\n",
        "            counts[aa] += 1\n",
        "    return {aa: counts[aa]/length for aa in aa_list}\n",
        "\n",
        "# Compute AAC for all sequences\n",
        "aac_data = [compute_aac_dict(seq) for seq in df['sequence']]\n",
        "aac_df = pd.DataFrame(aac_data, index=df.index)\n",
        "\n",
        "# Randomly select 5 amino acids\n",
        "random_aas = random.sample(aa_list, 5)\n",
        "print(\"Randomly selected amino acids:\", random_aas)\n",
        "\n",
        "# Prepare data for analysis\n",
        "X = aac_df[random_aas].values\n",
        "y = df['label'].values\n",
        "\n",
        "# PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# LDA (Fisher's Linear Discriminant)\n",
        "lda = LDA(n_components=1)\n",
        "X_lda = lda.fit_transform(X, y)\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# PCA plot\n",
        "plt.subplot(1, 2, 1)\n",
        "for label in np.unique(y):\n",
        "    plt.scatter(X_pca[y==label, 0], X_pca[y==label, 1], label=label)\n",
        "plt.xlabel('Principal Component 1')\n",
        "plt.ylabel('Principal Component 2')\n",
        "plt.title('PCA of Random 5 Amino Acids')\n",
        "plt.legend()\n",
        "\n",
        "# LDA plot\n",
        "plt.subplot(1, 2, 2)\n",
        "for label in np.unique(y):\n",
        "    plt.scatter(X_lda[y==label], np.zeros_like(X_lda[y==label]), label=label)\n",
        "plt.xlabel('Linear Discriminant')\n",
        "plt.yticks([])\n",
        "plt.title('LDA of Random 5 Amino Acids')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print explained variance for PCA\n",
        "print(\"PCA explained variance ratio:\", pca.explained_variance_ratio_)\n",
        "\n",
        "# Print LDA coefficients\n",
        "print(\"LDA coefficients:\", lda.coef_)"
      ],
      "metadata": {
        "id": "yRLmIiMbpWKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm  # for progress bar\n",
        "\n",
        "# Assuming df has 'sequence' and 'label' columns\n",
        "aa_list = ['A','C','D','E','F','G','H','I','K','L',\n",
        "           'M','N','P','Q','R','S','T','V','W','Y']\n",
        "\n",
        "def compute_aac_dict(sequence):\n",
        "    seq = sequence.upper()\n",
        "    length = len(seq)\n",
        "    counts = {aa: 0 for aa in aa_list}\n",
        "    for aa in seq:\n",
        "        if aa in counts:\n",
        "            counts[aa] += 1\n",
        "    return {aa: counts[aa]/length for aa in aa_list}\n",
        "\n",
        "# Compute AAC for all sequences\n",
        "aac_data = [compute_aac_dict(seq) for seq in df['sequence']]\n",
        "aac_df = pd.DataFrame(aac_data, index=df.index)\n",
        "X_all = aac_df[aa_list].values\n",
        "y = df['label'].map({'LLPS': 1, 'non-LLPS': 0}).values  # Convert to binary\n",
        "\n",
        "# Function to evaluate feature combination\n",
        "def evaluate_features(features):\n",
        "    X = aac_df[list(features)].values\n",
        "\n",
        "    # PCA + LDA evaluation\n",
        "    try:\n",
        "        # Reduce to 2 components with PCA\n",
        "        pca = PCA(n_components=2)\n",
        "        X_pca = pca.fit_transform(X)\n",
        "\n",
        "        # Apply LDA on PCA results\n",
        "        lda = LDA()\n",
        "        lda.fit(X_pca, y)\n",
        "        X_lda = lda.transform(X_pca)\n",
        "\n",
        "        # Get predictions\n",
        "        y_pred = lda.predict(X_pca)\n",
        "        acc = accuracy_score(y, y_pred)\n",
        "\n",
        "        # Return both accuracy and the features\n",
        "        return acc, features\n",
        "    except:\n",
        "        # In case of any error (e.g., when LDA fails)\n",
        "        return 0.0, features\n",
        "\n",
        "# Evaluate all possible 5-feature combinations\n",
        "all_combinations = list(combinations(aa_list, 5))\n",
        "results = []\n",
        "\n",
        "print(f\"Evaluating {len(all_combinations)} combinations...\")\n",
        "for combo in tqdm(all_combinations):\n",
        "    acc, features = evaluate_features(combo)\n",
        "    results.append((acc, features))\n",
        "\n",
        "# Sort results by accuracy (descending)\n",
        "results.sort(reverse=True, key=lambda x: x[0])\n",
        "\n",
        "# Display top 10 combinations\n",
        "print(\"\\nTop 10 performing 5-feature combinations:\")\n",
        "for i, (acc, features) in enumerate(results[:10], 1):\n",
        "    print(f\"{i}. Features: {features} | Accuracy: {acc:.4f}\")\n",
        "\n",
        "# Best combination\n",
        "best_acc, best_features = results[0]\n",
        "print(f\"\\nBest 5-feature combination: {best_features} with accuracy {best_acc:.4f}\")\n",
        "\n",
        "# Generate accuracy matrix for all features\n",
        "feature_performance = {aa: 0 for aa in aa_list}\n",
        "for acc, features in results:\n",
        "    for aa in features:\n",
        "        feature_performance[aa] += acc\n",
        "\n",
        "# Normalize by number of appearances\n",
        "for aa in feature_performance:\n",
        "    feature_performance[aa] /= len([1 for _, features in results if aa in features])\n",
        "\n",
        "print(\"\\nAverage accuracy contribution of each amino acid:\")\n",
        "for aa, score in sorted(feature_performance.items(), key=lambda x: -x[1]):\n",
        "    print(f\"{aa}: {score:.4f}\")\n",
        "\n",
        "# Visualize top combinations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "top_n = 10\n",
        "top_accs = [acc for acc, _ in results[:top_n]]\n",
        "top_feature_sets = [','.join(feats) for _, feats in results[:top_n]]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.barh(range(top_n), top_accs[::-1], color='skyblue')\n",
        "plt.yticks(range(top_n), top_feature_sets[::-1])\n",
        "plt.xlabel('Accuracy')\n",
        "plt.title(f'Top {top_n} 5-Feature Combinations Performance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5NgKcmVik3nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Analyzing {len(df)} proteins in the dataset\")"
      ],
      "metadata": {
        "id": "vHmMiu2HqzBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- Load Data (Assuming df has 'sequence' and 'label') ---\n",
        "aa_list = ['A','C','D','E','F','G','H','I','K','L',\n",
        "           'M','N','P','Q','R','S','T','V','W','Y']\n",
        "\n",
        "# --- Compute AAC (Amino Acid Composition) ---\n",
        "def compute_aac(sequence):\n",
        "    seq = sequence.upper()\n",
        "    length = len(seq)\n",
        "    return {aa: seq.count(aa)/length for aa in aa_list}\n",
        "\n",
        "# Create AAC DataFrame\n",
        "aac_data = [compute_aac(seq) for seq in df['sequence']]\n",
        "aac_df = pd.DataFrame(aac_data)\n",
        "y = df['label'].map({'LLPS': 1, 'non-LLPS': 0})  # Binary labels\n",
        "\n",
        "# --- LDA Model ---\n",
        "lda = LDA()\n",
        "\n",
        "# --- Evaluate with 5-Fold Cross-Validation ---\n",
        "cv_scores = cross_val_score(lda, aac_df, y, cv=5, scoring='accuracy')\n",
        "mean_accuracy = np.mean(cv_scores)\n",
        "std_accuracy = np.std(cv_scores)\n",
        "\n",
        "print(f\"LDA Mean Accuracy (5-Fold CV): {mean_accuracy:.4f} Â± {std_accuracy:.4f}\")\n",
        "\n",
        "# --- Train LDA on Full Data (for feature analysis) ---\n",
        "lda.fit(aac_df, y)\n",
        "\n",
        "# --- Get Feature Coefficients (Importance) ---\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Amino Acid': aa_list,\n",
        "    'LDA Coefficient': lda.coef_[0]\n",
        "}).sort_values('LDA Coefficient', ascending=False)\n",
        "\n",
        "print(\"\\nTop Discriminative Amino Acids:\")\n",
        "print(feature_importance.head(10))"
      ],
      "metadata": {
        "id": "zeoqSzxVrW6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn.model_selection import cross_val_score\n",
        "# from itertools import combinations\n",
        "# import random\n",
        "# from tqdm import tqdm\n",
        "\n",
        "# aa_list = ['A','C','D','E','F','G','H','I','K','L',\n",
        "#            'M','N','P','Q','R','S','T','V','W','Y']\n",
        "\n",
        "# def compute_aac(sequence):\n",
        "#     seq = sequence.upper()\n",
        "#     length = len(seq)\n",
        "#     return {aa: seq.count(aa)/length for aa in aa_list}\n",
        "\n",
        "# aac_data = [compute_aac(seq) for seq in df['sequence']]\n",
        "# aac_df = pd.DataFrame(aac_data)\n",
        "# y = df['label'].map({'LLPS': 1, 'non-LLPS': 0})\n",
        "\n",
        "# clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "# clf.fit(aac_df, y)\n",
        "\n",
        "# top_10_aa = aac_df.columns[np.argsort(clf.feature_importances_)[-10:]].tolist()\n",
        "# print(f\"Top 10 Candidate Amino Acids: {top_10_aa}\")\n",
        "\n",
        "# candidate_combos = list(combinations(top_10_aa, 5))\n",
        "# random.shuffle(candidate_combos)\n",
        "\n",
        "# best_acc = 0\n",
        "# best_combo = None\n",
        "\n",
        "# for combo in tqdm(candidate_combos[:500], desc=\"Testing Top Combos\"):  # Early stop after 500\n",
        "#     X = aac_df[list(combo)]\n",
        "#     acc = cross_val_score(clf, X, y, cv=3, scoring='accuracy').mean()  # 3-fold for speed\n",
        "#     if acc > best_acc:\n",
        "#         best_acc = acc\n",
        "#         best_combo = combo\n",
        "#         print(f\"New Best: {combo} | Accuracy: {acc:.4f}\")\n",
        "\n",
        "# print(f\"\\nðŸ”¥ Best 5 Features: {best_combo} | Accuracy: {best_acc:.4f}\")\n",
        "# clf_final = RandomForestClassifier(n_estimators=200, random_state=42)\n",
        "# clf_final.fit(aac_df[list(best_combo)], y)\n",
        "\n",
        "# pd.Series(clf_final.feature_importances_, index=best_combo).sort_values().plot.barh()\n",
        "# plt.xlabel(\"Importance\")\n",
        "# plt.title(\"Top 5 Feature Importance\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "aG81ASNQtpVa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()  # Opens a file picker dialog|"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "YIv1X30ClhN1",
        "outputId": "5e693f37-7830-4661-e73f-59f10586f446"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-62da16af-9edb-4198-9c65-15aa96c2598c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-62da16af-9edb-4198-9c65-15aa96c2598c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load protein data from LLPS.xls and build feature dictionary with random values whenever missing\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Load the Excel file (must be uploaded to Colab first)\n",
        "df = pd.read_excel(\"LLPS.xls\")\n",
        "\n",
        "# Preview column names (for your reference; remove/comment out if you donâ€™t need to see this)\n",
        "print(\"Columns in sheet:\", list(df.columns))\n",
        "\n",
        "# The list of features you expect\n",
        "feature_columns = [\n",
        "    \"molecular_weight\", \"aromaticity\", \"hydrophobicity\", \"instability_index\",\n",
        "    \"aliphatic_index\", \"isoelectric_point\", \"net_charge_pH7\", \"flexibility\",\n",
        "    \"volume_mean\", \"polarity_mean\", \"charge_density\", \"entropy_shannon\",\n",
        "    \"percent_disorder\", \"fraction_hydrophobic\", \"fraction_polar\",\n",
        "    \"fraction_charged\", \"fraction_positive\", \"fraction_negative\",\n",
        "    \"temperature_optimum\", \"ph_optimum\"\n",
        "]\n",
        "\n",
        "# Create a nested dictionary: protein_name -> {feature_name: value}\n",
        "protein_feature_dict = {}\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    protein_name = row.get(\"Protein name\", None)\n",
        "    if protein_name is None:\n",
        "        # If your column is named differently, fix it here\n",
        "        continue\n",
        "\n",
        "    features = {}\n",
        "    for feat in feature_columns:\n",
        "        if feat in df.columns:\n",
        "            raw_val = row[feat]\n",
        "            # If the cell is '-' (as a string) or is NaN, assign a random float between 0 and 1\n",
        "            if (isinstance(raw_val, str) and raw_val.strip() == \"-\") or pd.isna(raw_val):\n",
        "                val = random.random()\n",
        "            else:\n",
        "                val = raw_val\n",
        "        else:\n",
        "            # Column not present at all â†’ give a random value\n",
        "            val = random.random()\n",
        "\n",
        "        features[feat] = val\n",
        "\n",
        "    protein_feature_dict[protein_name] = features\n",
        "\n",
        "# Now print each protein and all of its features\n",
        "for protein, feats in protein_feature_dict.items():\n",
        "    print(f\"{protein}:\")\n",
        "    for feat_name, value in feats.items():\n",
        "        print(f\"  {feat_name}: {value}\")\n",
        "    print()\n"
      ],
      "metadata": {
        "id": "aanKXgQ76R4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def funct(dict):\n",
        "    keys = list(dict.keys())\n",
        "    if len(keys) < 5:\n",
        "        raise ValueError(\"Dictionary must contain at least 5 keys\")\n",
        "    combinations = list(itertools.combinations(keys, 5))\n",
        "    return combinations\n",
        "\n",
        "feature_dict = {\n",
        "    'hydrophobicity': 0.5,\n",
        "    'aromaticity': 0.3,\n",
        "    'isoelectric_point': 7.0,\n",
        "    'net_charge_pH7': -1.2,\n",
        "    'instability_index': 45.0,\n",
        "    'molecular_weight': 25000,\n",
        "    'flexibility': 0.8,\n",
        "    'volume_mean': 120.5,\n",
        "    'polarity_mean': 8.2,\n",
        "    'fraction_hydrophobic': 0.4,\n",
        "    'fraction_polar': 0.3,\n",
        "    'fraction_charged': 0.2,\n",
        "    'fraction_positive': 0.1,\n",
        "    'fraction_negative': 0.1,\n",
        "    'percent_disorder': 0.6,\n",
        "    'aliphatic_index': 85.0,\n",
        "    'charge_density': -0.0001,\n",
        "    'entropy_shannon': 2.5,\n",
        "    'temperature_optimum': 37.0,\n",
        "    'ph_optimum': 7.4\n",
        "}\n",
        "\n",
        "combinations = funct(feature_dict)\n",
        "\n",
        "# Print first 5 combinations as example\n",
        "print(\"Total combinations:\", len(combinations))\n",
        "print(\"First 5 combinations:\")\n",
        "for combo in combinations:\n",
        "    print(combo)"
      ],
      "metadata": {
        "id": "KcQFWGD3pNwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "\n",
        "np.random.seed(42)\n",
        "num_samples = 100\n",
        "feature_names = ['hydrophobicity', 'aromaticity', 'isoelectric_point', 'net_charge_pH7','instability_index', 'molecular_weight', 'flexibility', 'volume_mean','polarity_mean', 'fraction_hydrophobic', 'fraction_polar', 'fraction_charged','fraction_positive', 'fraction_negative', 'percent_disorder','aliphatic_index', 'charge_density', 'entropy_shannon','temperature_optimum', 'ph_optimum']\n",
        "X = np.random.randn(num_samples, len(feature_names))\n",
        "y = np.random.randint(0,2,size=num_samples)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# saare sequence banane ek liye easy way\n",
        "all_combinations = list(combinations(range(len(feature_names)),6))\n",
        "print(f\"Total combinations to process: {len(all_combinations)}\")\n",
        "\n",
        "def funct_PCA(X_subset, n_components=2):\n",
        "    pca = PCA(n_components=n_components)\n",
        "    pca.fit(X_subset)\n",
        "    return sum(pca.explained_variance_ratio_)\n",
        "\n",
        "def funct_LDA(X_subset, y):\n",
        "    try:\n",
        "        lda = LDA()\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X_subset, y, test_size=0.2, random_state=42)\n",
        "        lda.fit(X_train, y_train)\n",
        "        return lda.score(X_test, y_test)\n",
        "    except ValueError:  #agar lda nhii chala\n",
        "        return 0.0\n",
        "\n",
        "accuracy_dict = {}\n",
        "\n",
        "for idx, combo in enumerate(tqdm(all_combinations, desc=\"Processing combinations\")):\n",
        "    X_subset = X_scaled[:, combo]\n",
        "    lda_accuracy = funct_LDA(X_subset, y)\n",
        "    accuracy_dict[idx] = lda_accuracy\n",
        "\n",
        "best_idx = max(accuracy_dict, key=accuracy_dict.get)\n",
        "best_accuracy = accuracy_dict[best_idx]\n",
        "best_features = [feature_names[i] for i in all_combinations[best_idx]]\n",
        "print(f\"\\nBest combination found (index {best_idx}):\")\n",
        "print(f\"Features: {best_features}\")\n",
        "print(f\"Accuracy: {best_accuracy:.4f}\")\n",
        "results_df = pd.DataFrame({'combination_index': list(accuracy_dict.keys()),'feature_indices': [all_combinations[idx] for idx in accuracy_dict.keys()],'feature_names': [[feature_names[i] for i in all_combinations[idx]] for idx in accuracy_dict.keys()],'accuracy': list(accuracy_dict.values())})\n",
        "results_df = results_df.sort_values('accuracy', ascending=False)\n",
        "\n",
        "results_df.to_csv('feature_combination_results.csv', index=False)\n",
        "print(\"\\nSaved all results to 'feature_combination_results.csv'\")\n",
        "\n",
        "#plotting best 10 , common features will be most influencing one in fucntion\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_results = results_df.head(10)\n",
        "plt.barh(\n",
        "    y=[str(feats) for feats in top_results['feature_names']],\n",
        "    width=top_results['accuracy'],\n",
        "    color='skyblue'\n",
        ")\n",
        "plt.xlabel('Classification Accuracy')\n",
        "plt.title('Top 10 Feature Combinations by LDA Accuracy')\n",
        "plt.gca().invert_yaxis()  # Show best at top\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R2sMiq-qpfGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_PTjUhxfzrVP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}